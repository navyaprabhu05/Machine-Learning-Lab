{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AcvqA0Nd1OLy"
      },
      "outputs": [],
      "source": [
        "# Install libraries (if needed in Colab)\n",
        "!pip install -q scikit-learn pandas matplotlib seaborn\n",
        "\n",
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "metadata": {
        "id": "ZN-OWrxG1oWh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('rounded_hours_student_scores.csv')\n",
        "\n",
        "# See column names\n",
        "print(data.columns)\n",
        "\n",
        "# See first 5 rows\n",
        "print(data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6TksYZf4Mtl",
        "outputId": "16981f9c-4fdf-425b-f336-9a561a24f1f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Hours', 'Scores'], dtype='object')\n",
            "   Hours  Scores\n",
            "0    1.1      41\n",
            "1    1.2      40\n",
            "2    1.4      38\n",
            "3    1.5      39\n",
            "4    1.6      36\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Load dataset from CSV\n",
        "data = pd.read_csv('rounded_hours_student_scores.csv')\n",
        "\n",
        "# Keep only cgpa and lpa (remove placed column)\n",
        "data = data[['Hours', 'Scores']]\n",
        "\n",
        "# Separate features and target\n",
        "X = data[['Hours']]\n",
        "y = data['Scores']\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Add bias term (for manual linear regression calculations)\n",
        "X_train_scaled = np.c_[np.ones(X_train_scaled.shape[0]), X_train_scaled]\n",
        "X_test_scaled = np.c_[np.ones(X_test_scaled.shape[0]), X_test_scaled]\n",
        "\n",
        "print(\"Data loaded and preprocessed!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRcBDiZt4XGF",
        "outputId": "be03c66a-e22d-4f41-e2ca-483be5629b4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded and preprocessed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent_vanilla(X, y, lr=0.1, n_iters=1000):\n",
        "    m, n = X.shape\n",
        "    theta = np.zeros(n)  # Initialize weights\n",
        "    for _ in range(n_iters):\n",
        "        y_pred = X @ theta\n",
        "        error = y_pred - y\n",
        "        gradients = (1/m) * X.T @ error\n",
        "        theta -= lr * gradients\n",
        "    return theta"
      ],
      "metadata": {
        "id": "54ghumxL4bS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent_l2(X, y, lr=0.1, n_iters=5000, lambda_=0.1):\n",
        "    m, n = X.shape\n",
        "    theta = np.zeros(n)\n",
        "    for _ in range(n_iters):\n",
        "        y_pred = X @ theta\n",
        "        error = y_pred - y\n",
        "        gradients = (1/m) * (X.T @ error + lambda_ * np.r_[0, theta[1:]])  # Bias not regularized\n",
        "        theta -= lr * gradients\n",
        "    return theta"
      ],
      "metadata": {
        "id": "A4icmP-C4eGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent_l1(X, y, lr=0.1, n_iters=1000, lambda_=0.1):\n",
        "    m, n = X.shape\n",
        "    theta = np.zeros(n)\n",
        "    for _ in range(n_iters):\n",
        "        y_pred = X @ theta\n",
        "        error = y_pred - y\n",
        "        gradients = (1/m) * X.T @ error\n",
        "        # Add L1 subgradient (sign of theta) except bias term\n",
        "        gradients[1:] += lambda_ * np.sign(theta[1:])\n",
        "        theta -= lr * gradients\n",
        "    return theta"
      ],
      "metadata": {
        "id": "yyyhJeGq4f_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent_elasticnet(X, y, lr=0.1, n_iters=1000, lambda1=0.1, lambda2=0.1):\n",
        "    m, n = X.shape\n",
        "    theta = np.zeros(n)\n",
        "    for _ in range(n_iters):\n",
        "        y_pred = X @ theta\n",
        "        error = y_pred - y\n",
        "        gradients = (1/m) * X.T @ error\n",
        "        gradients[1:] += lambda1 * np.sign(theta[1:]) + lambda2 * theta[1:]\n",
        "        theta -= lr * gradients\n",
        "    return theta"
      ],
      "metadata": {
        "id": "3jRuagFD4ijV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(X_test, y_test, theta, name=\"Model\"):\n",
        "    y_pred = X_test @ theta\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    error_percent = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
        "\n",
        "    print(f\"\\nðŸ“Š {name}\")\n",
        "    print(f\"   âž¤ Mean Squared Error (MSE): {mse:.4f}\")\n",
        "    print(f\"   âž¤ RÂ² Score: {r2:.4f}\")\n",
        "    print(f\"   âž¤ Mean Absolute Percentage Error: {error_percent:.2f}%\")\n",
        "\n",
        "    return {\"Model\": name, \"MSE\": mse, \"RÂ²\": r2, \"Error %\": error_percent}"
      ],
      "metadata": {
        "id": "Cq6dixAa4kzV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "\n",
        "# Vanilla Linear Regression\n",
        "theta_vanilla = gradient_descent_vanilla(X_train_scaled, y_train)\n",
        "results.append(evaluate_model(X_test_scaled, y_test, theta_vanilla, \"Vanilla Linear Regression\"))\n",
        "\n",
        "# L2 Regularization (Ridge)\n",
        "theta_l2 = gradient_descent_l2(X_train_scaled, y_train, lambda_=9)\n",
        "results.append(evaluate_model(X_test_scaled, y_test, theta_l2, \"L2 Regularization (Ridge)\"))\n",
        "\n",
        "# L1 Regularization (Lasso)\n",
        "theta_l1 = gradient_descent_l1(X_train_scaled, y_train, lambda_=0.01)\n",
        "results.append(evaluate_model(X_test_scaled, y_test, theta_l1, \"L1 Regularization (Lasso)\"))\n",
        "\n",
        "# ElasticNet (L1 + L2)\n",
        "theta_elastic = gradient_descent_elasticnet(X_train_scaled, y_train, lambda1=0.1, lambda2=0.1)\n",
        "results.append(evaluate_model(X_test_scaled, y_test, theta_elastic, \"ElasticNet (L1 + L2)\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQPq6BhW4m1V",
        "outputId": "f5390832-893e-465c-8cf0-8f9d9b1b43d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“Š Vanilla Linear Regression\n",
            "   âž¤ Mean Squared Error (MSE): 15.6678\n",
            "   âž¤ RÂ² Score: 0.5810\n",
            "   âž¤ Mean Absolute Percentage Error: 5.63%\n",
            "\n",
            "ðŸ“Š L2 Regularization (Ridge)\n",
            "   âž¤ Mean Squared Error (MSE): 16.7879\n",
            "   âž¤ RÂ² Score: 0.5510\n",
            "   âž¤ Mean Absolute Percentage Error: 6.08%\n",
            "\n",
            "ðŸ“Š L1 Regularization (Lasso)\n",
            "   âž¤ Mean Squared Error (MSE): 15.6747\n",
            "   âž¤ RÂ² Score: 0.5808\n",
            "   âž¤ Mean Absolute Percentage Error: 5.64%\n",
            "\n",
            "ðŸ“Š ElasticNet (L1 + L2)\n",
            "   âž¤ Mean Squared Error (MSE): 16.3267\n",
            "   âž¤ RÂ² Score: 0.5633\n",
            "   âž¤ Mean Absolute Percentage Error: 5.93%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "86qkV8WE8G5p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}